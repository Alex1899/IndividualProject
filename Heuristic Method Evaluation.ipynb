{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import evaluate_form\n",
    "from JointAngles import JointAngles\n",
    "from Parser import parse_frames\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front_raise\n",
      "Predicting...\n",
      "pred:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "true: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Done!\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.22      1.00      0.36        10\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.11      0.50      0.18        46\n",
      "weighted avg       0.05      0.22      0.08        46\n",
      "\n",
      "Accuracy score: 0.21739130434782608\n",
      "shoulder_press\n",
      "Predicting...\n",
      "pred:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "true: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Done!\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.45      1.00      0.62        25\n",
      "\n",
      "    accuracy                           0.45        56\n",
      "   macro avg       0.22      0.50      0.31        56\n",
      "weighted avg       0.20      0.45      0.28        56\n",
      "\n",
      "Accuracy score: 0.44642857142857145\n",
      "triceps_pushdown\n",
      "Predicting...\n",
      "pred:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "true: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Done!\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.24      1.00      0.39        10\n",
      "\n",
      "    accuracy                           0.24        41\n",
      "   macro avg       0.12      0.50      0.20        41\n",
      "weighted avg       0.06      0.24      0.10        41\n",
      "\n",
      "Accuracy score: 0.24390243902439024\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'C:\\\\Users\\\\ak5u16\\\\Desktop\\\\IndividualProject\\\\keypoints_for_all'\n",
    "folder_paths = glob.glob(os.path.join(input_folder, '*'))  \n",
    "\n",
    "y_predictions = []\n",
    "y_correct_labels = []\n",
    "class_reports = []\n",
    "\n",
    "for folder in folder_paths:\n",
    "    folder_name = os.path.basename(folder)\n",
    "    name = folder_name.split(' ', 1)[0] + '_' + folder_name.split(' ', 1)[1]  \n",
    "    print(name)\n",
    "    keypoints_folders = glob.glob(os.path.join(folder, name + '*'))  \n",
    "    for kf in keypoints_folders:\n",
    "        if '_correct' in os.path.basename(kf):\n",
    "            y_correct_labels.append(0)\n",
    "        else:\n",
    "            y_correct_labels.append(1)\n",
    "    \n",
    "    print('Predicting...')\n",
    "    for kf2 in keypoints_folders:\n",
    "        frame_pose = parse_frames(kf)\n",
    "        y_predictions.append(evaluate_form(frame_pose, folder_name, False))\n",
    "    \n",
    "    print('pred:' + str(y_predictions))\n",
    "    print('true: ' + str(y_correct_labels))\n",
    "    print('Done!\\n')        \n",
    "    if len(y_predictions) == len(y_correct_labels):\n",
    "        print(classification_report(y_correct_labels, y_predictions))\n",
    "        print('Accuracy score: ' + str(accuracy_score(y_correct_labels, y_predictions)))\n",
    "        y_predictions = []\n",
    "        y_correct_labels = []\n",
    "    else:\n",
    "        print('Error')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
